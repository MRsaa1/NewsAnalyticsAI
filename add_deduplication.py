#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π
"""

import sqlite3
from difflib import SequenceMatcher
import re

def similarity(a, b):
    """–í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –¥–≤—É—Ö —Å—Ç—Ä–æ–∫"""
    return SequenceMatcher(None, a.lower(), b.lower()).ratio()

def extract_keywords(text):
    """–ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º –≤–∞–∂–Ω—ã–µ —Å–ª–æ–≤–∞
    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those'}
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ –¥–ª–∏–Ω–Ω–µ–µ 3 —Å–∏–º–≤–æ–ª–æ–≤
    words = re.findall(r'\b[a-zA-Z]{4,}\b', text.lower())
    keywords = [word for word in words if word not in stop_words]
    
    return set(keywords)

def find_duplicates():
    """–ù–∞—Ö–æ–¥–∏–º –¥—É–±–ª–∏–∫–∞—Ç—ã –Ω–æ–≤–æ—Å—Ç–µ–π"""
    print("üöÄ –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π...")
    
    conn = sqlite3.connect('signals.db')
    cursor = conn.cursor()
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏
    cursor.execute("""
        SELECT id, title, sector, impact
        FROM signals 
        ORDER BY impact DESC
    """)
    
    all_news = cursor.fetchall()
    print(f"üìä –í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(all_news)}")
    
    duplicates_to_remove = []
    processed = set()
    
    for i, (id1, title1, sector1, impact1) in enumerate(all_news):
        if id1 in processed:
            continue
            
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
        keywords1 = extract_keywords(title1)
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏
        for j, (id2, title2, sector2, impact2) in enumerate(all_news[i+1:], i+1):
            if id2 in processed:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            title_similarity = similarity(title1, title2)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            keywords2 = extract_keywords(title2)
            keyword_overlap = len(keywords1 & keywords2) / len(keywords1 | keywords2) if keywords1 | keywords2 else 0
            
            # –ï—Å–ª–∏ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏ (–ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É –∏–ª–∏ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º)
            if title_similarity > 0.7 or keyword_overlap > 0.6:
                # –í—ã–±–∏—Ä–∞–µ–º –Ω–æ–≤–æ—Å—Ç—å —Å –º–µ–Ω—å—à–∏–º impact
                if impact1 < impact2:
                    duplicates_to_remove.append(id1)
                    processed.add(id1)
                    print(f"üóëÔ∏è –£–¥–∞–ª—è–µ–º: {title1[:50]}... (impact: {impact1})")
                    break
                else:
                    duplicates_to_remove.append(id2)
                    processed.add(id2)
                    print(f"üóëÔ∏è –£–¥–∞–ª—è–µ–º: {title2[:50]}... (impact: {impact2})")
    
    # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    if duplicates_to_remove:
        cursor.execute(f"""
            DELETE FROM signals 
            WHERE id IN ({','.join(['?' for _ in duplicates_to_remove])})
        """, duplicates_to_remove)
        
        conn.commit()
        print(f"\nüéâ –£–¥–∞–ª–µ–Ω–æ {len(duplicates_to_remove)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
    else:
        print("\n‚úÖ –î—É–±–ª–∏–∫–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    conn.close()

if __name__ == "__main__":
    find_duplicates()
